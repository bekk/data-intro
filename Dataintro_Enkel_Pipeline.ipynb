{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataintro Enkel Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop: Introduksjon til dataflyt og transformasjon\n",
        "\n",
        "**Du vil l칝re:**\n",
        "- Helt overordnet hva dataflyt og transformasjon er, hva det inneb칝rer og hvordan det utf칮res i praksis\n",
        "- Litt om Google Cloud Storage og Google BigQuery\n",
        "- 칀 laste inn, hente ut og jobbe med data fra Google BigQuery\n",
        "- Gj칮re enkle transformasjoner ved hjelp av datamanipuleringsverkt칮y\n",
        "- Lage et nytt og rikere datasett med data fra flere kilder \n",
        "\n",
        "**Du vil _ikke_ l칝re:**\n",
        "- Hvordan man setter opp en faktisk dataflyt eller lignende i Google Cloud Platform\n",
        "- Spesifikke detaljer om verkt칮y som Google Cloud Platform (GCP), Pandas, Matplotlib, Keras, Tensorflow og liknende\n",
        "\n",
        "\n",
        "游눠 Oppgave 1-4 er utforskende i GCP og kan timeboxes til ca. 10 minutter."
      ],
      "metadata": {
        "id": "raflZ3eh1f4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Relevante GCP-komponenter for workshopen\n",
        "## Google Cloud Storage\n",
        "\n",
        "Google Cloud Storage (GCS) er rett og slett et filomr친de hvor vi kan lagre filer p친 ulike formater, med b친de strukturerte og ustrukturerte data. GCS er et fint landingspunkt for data, slik at du kan jobbe uavhengig av systemene dataene stammer fra (f.eks eksterne APIer). \n",
        "\n",
        "\n",
        "Vi bruker ofte begrepet \"storage bucket\" for en logisk oppdeling av et filomr친de (noe tilsvarende som en filmappe p친 din maskin).\n",
        "\n",
        "Data i en storage bucket er som regel ikke klargjort for analyseform친l. Vi 칮nsker derfor 친 prosessere og flytte den til et annet verkt칮y. Et slikt verkt칮y kan v칝re Google BigQuery, som er en database tilpasset analyse. Dette kan videre kobles opp mot visualiserings- og modelleringsverkt칮y som Colab-notebooks.\n",
        "\n",
        "## Google BigQuery\n",
        "\n",
        "BigQuery er en SQL-basert database som er optimalisert for analyse. I motsetning til tradisjonelle SQL-databaser er BigQuery kolonnebasert istedenfor radbasert. Dette gj칮r den optimalisert til 친 regne ut aggregerte tall. BigQuery takler tabeller med et h칮yt antall kolonner sv칝rt godt."
      ],
      "metadata": {
        "id": "DPfwNsUoPddk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Oppgaver\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wQ3gSFzt9Dnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oppgave 1: Bli kjent med Google Cloud Storage (GCS)\n",
        "\n",
        "G친 til [Google Cloud Console](https://console.cloud.google.com), logg inn med din epost og velg prosjekt \"data-intro\" oppe i venstre hj칮rne.\n",
        "\n",
        "I Google Cloud Console (GUI) for prosjektet (data-intro), finn Google Cloud Storage. Du kan enten finne GCS via menyen eller s칮ke etter den i s칮kefeltet. \n",
        "\n",
        "I prosjektet finner du en bucket med to ulike datasett. Hva finner du ut om disse datasettene (metadata)?\n",
        "\n",
        "a) Hvilken filtype er de?\n",
        "  \n",
        "  \n",
        "b) Hvor store er filene?\n",
        "  "
      ],
      "metadata": {
        "id": "ydTsudgDBZMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Svar a:\n",
        "# Svar b:"
      ],
      "metadata": {
        "id": "jTiSwTo9_ffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oppgave 2: Importer dataen til BigQuery\n",
        "\n",
        "For 친 se n칝rmere p친 innholdet i datasettene 칮nsker vi 친 flytte de til BigQuery. Gj칮r f칮lgende i [Google Cloud Console](https://console.cloud.google.com):\n",
        "\n",
        "1. Finn BigQuery i menyen\n",
        "2. Velg BigQuery-prosjektet \"Data intro\" og deretter marker datasettet bysykkel_main\n",
        "3. I menylinjen oppe til h칮yre, velg \"Create table\". \n",
        "4. Under \"Source\" kan du velge datakilden din. Vi 칮nsker 친 velge bysykkeldatasettet fra Storage Bucket. Filformatet fant du i oppgave 1. \n",
        "5. Under \"Destination\" kan du kalle den nye tabellen din `bysykkel_(gruppenavn)`. \n",
        "6. La BigQuery definere skjema for deg, og behold ellers standard innstillingene.\n",
        "7. Trykk p친 \"Create Table\" \n",
        "\n",
        "Datasettet er n친 lastet inn i BigQuery."
      ],
      "metadata": {
        "id": "9tCc63aZWUgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oppgave 3: Bli kjent med datasettet\n",
        "\n",
        "N친r vi markerer tabellen i BigQuery som vi laget i forrige oppgave ser vi en rekke metadata, samt en preview-funksjon for 친 unders칮ke radene i datasettet v친rt.\n",
        "\n",
        "Hva finner du ut om skjema (datatypene) og innholdet?"
      ],
      "metadata": {
        "id": "be4ImxshDMwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## Oppgave 4: V칝rdata!\n",
        "Vi har allerede lastet inn v칝rdatasettet inn i BigQuery (`v칝rdata_oslo`).\n",
        "Hva finner du ut om skjema (datatypene) og innholdet for dette datasettet?\n",
        "\n"
      ],
      "metadata": {
        "id": "cI5dylecWZnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oppgave 5: Lage et utvidet datasett\n",
        "Vi 칮nsker 친 sl친 sammen de to datasettene slik at vi kan gj칮re analyse p친 tvers av disse. \n",
        "\n",
        "游눠 **NB! Du m친 jobbe i din egen notebook-kopi om du ikke allerede har gjort det. Se avsnittet \"Hvordan komme i gang\" p친 Github for detaljer**\n",
        "\n",
        "1. Koble deg til BigQuery. F칮rst m친 du autentisere deg (med din Bekk Google bruker som har tilgang til BigQuery). Kj칮r kodesnutten under for 친 gj칮re dette.\n"
      ],
      "metadata": {
        "id": "s9nSGug2NrRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate your Google Account\n",
        "# Doing so means you have access to various\n",
        "# resources connected to your account, such\n",
        "# as BigQuery tables, Storage buckets etc.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "eqEVQIJsT7K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under har vi en hjelpemetode for 친 laste inn datasettene dine fra BigQuery. Kj칮r denne kodesnutten ogs친. "
      ],
      "metadata": {
        "id": "CSvHGiNTegzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eksterne avhengigheter\n",
        "from google.cloud import bigquery_storage\n",
        "from google.cloud.bigquery_storage import types\n",
        "from google.cloud.bigquery_storage_v1 import enums\n",
        "import pandas\n",
        "\n",
        "#  params:\n",
        "#   project_id: String\n",
        "#   dataset_id: String\n",
        "#     table_id: String\n",
        "# \n",
        "#  return:\n",
        "#           df: Pandas DataFrame\n",
        "#\n",
        "def load_bigquery_data(project_id, dataset_id, table_id):\n",
        "    # Parse input-verdier til forventet filsti p친 Google BigQuery\n",
        "    table = f\"projects/{project_id}/datasets/{dataset_id}/tables/{table_id}\"\n",
        "    parent = \"projects/{}\".format(project_id)\n",
        "\n",
        "    # Instansier klient for enkel integrasjon mot BigQuery\n",
        "    bqstorageclient = bigquery_storage.BigQueryReadClient()\n",
        "\n",
        "    # Opprett en read-session mot en tabell i BigQuery\n",
        "    requested_session = types.ReadSession(\n",
        "        table=table,\n",
        "        data_format = enums.DataFormat.ARROW\n",
        "    )\n",
        "    read_session = bqstorageclient.create_read_session(\n",
        "        parent=parent,\n",
        "        read_session=requested_session,\n",
        "        max_stream_count=1,\n",
        "    )\n",
        "\n",
        "    # Les data fra BigQuery, putt i en liste med dataframes\n",
        "    stream = read_session.streams[0]\n",
        "    readRowsStream = bqstorageclient.read_rows(stream.name)\n",
        "    dfs = []\n",
        "    for page in readRowsStream.rows(read_session).pages:\n",
        "        dfs.append(page.to_dataframe())\n",
        "\n",
        "    # Sett flere dataframes sammen til 칠n\n",
        "    df = pandas.concat(dfs)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "AXXkkVCBUDEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  N친r du er autentisert, laster du inn bysykkel-datasettet til gruppen din, samt v칝rdatasettet inn i notebooken. Datasettene blir lastet inn som dataframes (som du kan lese mer om [her](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)). \n",
        "\n",
        "Vi kaller dataframesene henholdsvis `df_bysykkel` og `df_weather`.\n",
        "\n",
        "Kj칮r kodelinjene under og unders칮k innholdet."
      ],
      "metadata": {
        "id": "jyJPs0v4T-35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Husk 친 bytte ut med gruppen din sitt bysykkeldatasett\n",
        "df_bysykkel = load_bigquery_data(\"data-intro\", \"bysykkel_main\", \"bysykkel_[DITT_GRUPPENAVN]\")\n",
        "df_bysykkel.head()\n"
      ],
      "metadata": {
        "id": "DeeAWcm_Iyu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_weather = load_bigquery_data(\"data-intro\", \"bysykkel_main\", \"v칝rdata_oslo\")\n",
        "df_weather.head()"
      ],
      "metadata": {
        "id": "wJPseSt0YIzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Vi m친 finne en kolonne med fellesdata for 친 kunne sl친 sammen tabellene. S친 du noen fellesnevnere da du unders칮kte innholdet i tabellene?"
      ],
      "metadata": {
        "id": "ayDXtr1wJJfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DITT SVAR HER"
      ],
      "metadata": {
        "id": "CcnsieJ1Jq0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Et alternativ er 친 sl친 sammen tabellene basert p친 dato. V칝rdatasettet har en gjennomsnittstemperatur og en gjennomsnittsnedb칮rsmengde for hver dato. P친 bysykkeldatasettet har vi flere kolonner som inneholder dato, s친 her m친 vi velge en. Valget avhenger av hva vi 칮nsker 친 analysere. Dette datasettet er ikke s친 omfattende, s친 i v친rt eksempel velger vi 친 sl친 sammen p친 turens starttidspunkt (`started_at`).\n",
        "\n",
        "  Vi fors칮ker 친 sl친 sammen tabellene ved 친 bruke `started_at` i bysykkeldatasettet og `date` i v칝rdatasettet. [`merge`](https://pandas.pydata.org/docs/reference/api/pandas.merge.html)-funksjonen i pandas kan hjelpe oss.\n",
        "\n",
        "  Kj칮r kodelinjen under. St칮tte du p친 noen utfordringer? Hvorfor fungerer ikke dette?"
      ],
      "metadata": {
        "id": "Q_TKKnykJtzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_merged = pandas.merge(df_bysykkel, df_weather, left_on='started_at', right_on='date', how='left') \n"
      ],
      "metadata": {
        "id": "Oe9xW2LWwPjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details><summary>游뚿 L칮sningsforslag</summary>\n",
        "\n",
        "Ta en kikk p친 innholdet i disse to kolonnene. Ser det ut som datoformatet er det samme i de ulike tabellene? Her m친 vi gj칮re mer transformasjon f칮r vi kan fortsette!\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "vm8wD4UTKMsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oppgave 6: Rydde opp i datasettene\n",
        "Transformasjoner er en stor og viktig prosess n친r vi jobber med data. Ofte er datasettene vi har til r친dighet ikke p친 det formatet vi 칮nsker 친 ha de p친. 칀 transformere data betyr 친 gj칮re endringer, f.eks:\n",
        "- sl친 sammen datasett\n",
        "- endre p친 datatyper \n",
        "- fjerne duplikater \n",
        "- gj칮re utregninger med basis i andre kolonner\n",
        "- fjerne potensielle \"outliers\" som kan 칮delegge grunnlaget v친rt for analyse\n",
        "\n",
        "> 游빞 Prosessen over kalles ofte for 친 \"vaske\" data.\n",
        "\n",
        "Vi m친 f친 datokolonnene til 친 v칝re p친 samme format. En m친te vi kan gj칮re dette p친 er 친 fjerne klokkeslettet og kun bruke datodelen av `started_at`. Ulempen med dette er at vi da mister informasjon vi kanskje 칮nsker 친 bruke videre i analyse/innsiktsdelen. \n",
        "\n",
        "Vi l칮ser dette problemet med 친 lage en hjelpekolonne, alts친 en ny midlertidg kolonne som kun brukes n친r vi sl친r sammen datasettene\n",
        "\n",
        "1. Lag en ny kolonne i `df_bysykkel`, `trip_date`, som kun inneholder datoen fra kolonnen `started_at`.\n",
        "\n",
        "**游눠 Tips**: Pandas har en funksjon [`to_datetime`](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) som lar deg tilpasse tidspunkter\n",
        "\n"
      ],
      "metadata": {
        "id": "wJB6gAMbwtfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### DIN KODE HER\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "8YSrupR_w0x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details><summary>游뚿 L칮sningsforslag</summary>\n",
        "\n",
        "```\n",
        "df_bysykkel[\"trip_date\"] = pandas.to_datetime(df_bysykkel[\"started_at\"]).dt.strftime(\"%Y-%m-%d\") \n",
        "df_bysykkel.head()\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "RNdR-8VuM1Km"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Fors칮k 친 merge p친 nytt ved 친 bruke hjelpekolonnen `trip_date` ved 친 kj칮re kodelinjen under. Fungerer det 친 sl친 sammen n친? Hvordan ser datasettet ut?"
      ],
      "metadata": {
        "id": "fnxmSPiGN4b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = pandas.merge(df_bysykkel, df_weather, left_on='trip_date', right_on='date', how='left') \n",
        "df_merged.head()"
      ],
      "metadata": {
        "id": "O1AaLoZ9NzjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "<summary>游뚿 L칮sningsforslag</summary>  \n",
        "Det vil i prinsippet fungere, men det er likevel ikke riktig fordi kolonnene har ulike datatyper. Du kan sjekke hvilke datatyper dataframen din inneholder ved 친 bruke pandas \"dtypes\", f.eks df_bysykkel.dtypes\n",
        "\n",
        "Du kan lese mer om funksjonen dtypes [her](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dtypes.html)\n",
        "\n",
        "</details>\n",
        "\n"
      ],
      "metadata": {
        "id": "TcXCs_CZw3qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Gj칮r n칮dvendige endringer i kolonnen `trip_date` i bysykkeldatasettet og `date` i v칝rdatasettet for 친 kunne sl친 sammen.\n"
      ],
      "metadata": {
        "id": "E-QdbA1COWN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DIN KODE HER\n",
        "##\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "lR-0dx0cxB6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details><summary>游뚿 L칮sningsforslag</summary>\n",
        "Vi setter begge kolonnen til 친 v칝re av type datetime (datotid).\n",
        "\n",
        "```\n",
        "df_bysykkel[\"trip_date\"] = pandas.to_datetime(df_bysykkel[\"trip_date\"])\n",
        "df_weather[\"date\"] = pandas.to_datetime(df_weather[\"date\"])\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "ds7-9lC5OwUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. N친 skal det fungere 친 sl친 sammen datasettene! 游꿀 \n",
        "\n",
        " Vi 칮nsker 친 supplere hver rad av bysykkeldatasettet med v칝rdata fra den aktuelle dagen. Skriv kode under som oppn친r dette. \n",
        " Rekkef칮lgen og type join (left, right, outer etc) har noe 친 si n친r datasettene sl친s sammen.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vy9wVOCGyB_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DIN KODE HER\n",
        "##\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "30ZZiRcWyGdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "<summary>游뚿 L칮sningsforslag</summary>  \n",
        "\n",
        "```\n",
        "df_merged = df_bysykkel.merge(df_weather, left_on='trip_date', right_on='date', how='left')\n",
        "df_merged.head()\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "Ciq0pB9aTUlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. Kj칮r `dtypes` igjen. V칝rdata-kolonnene ser ikke ut til 친 v칝re av typen tall, men string. Det vil ikke fungere 친 gj칮re aggregeringer p친 strings. Hvorfor fungerer det ikke 친 gj칮re om kolonnen direkte?"
      ],
      "metadata": {
        "id": "vPrY9Nj9yLdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged[\"mean_temperature\"] = df_merged[\"mean_temperature\"].astype('float')\n",
        "df_merged[\"precipitation_amount\"] = df_merged[\"precipitation_amount\"].astype('float')"
      ],
      "metadata": {
        "id": "Y6lQfo3LUYn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>游뚿 L칮sningsforslag</summary>\n",
        "\n",
        "Kolonnen ser tilsynelatende ut til 친 kun best친 av tall. Hvis vi derimot inspiserer verdiene n칝rmere, ser vi at noen ganger forekommer strengen \"NULL\" som ikke er et tall. Pandas f친r derfor ikke til 친 gj칮re om datatypen f칮r vi gj칮r noe med dette.\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "V78SM-k7UZ5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Endre datatypen p친 nedb칮rskolonnen og temperaturkolonnen slik at det blir desimaltall."
      ],
      "metadata": {
        "id": "4sbgPwHLZgvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DIN KODE HER\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "m0GmJP7GYv9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>游뚿 L칮sningsforslag</summary>\n",
        "\n",
        "Vi m친 rydde opp i disse kolonnene ved 친 fjerne strengene 'NULL' f칮r vi kan endre datatypen til float. Vi kan bruke `replace` funksjonen til en dataframe.\n",
        "\n",
        "Vi kunne gjort om NULL til 0, men dette ville f친tt betydning for statistiske verdier som gjennomsnitt. Vi velger derfor 친 sette verdien \"blank\", som heter \"None\" i Python.\n",
        "\n",
        "```\n",
        "df_merged[\"mean_temperature\"] = df_merged[\"mean_temperature\"].replace('NULL',None).astype('float')\n",
        "df_merged[\"precipitation_amount\"] = df_merged[\"precipitation_amount\"].replace('NULL',None).astype('float')\n",
        "\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "OoBYPUz_aCFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "7. Til slutt: Rydd opp ved 친 fjerne hjelpekolonnen fra `df_merged`\n"
      ],
      "metadata": {
        "id": "sk8NH-K9Uo6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## DIN KODE HER\n",
        "##\n",
        "##\n",
        "##"
      ],
      "metadata": {
        "id": "GpdDnOQoyPbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "<summary>游뚿 L칮sningsforslag</summary> \n",
        "\n",
        "```\n",
        "df_merged = df_merged.drop(columns=\"trip_date\")\n",
        "df_merged.head()\n",
        "\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "-DNOuBMqW-Kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Vi har n친 et utvidet datasett! 游꿀游볙游꿁\n",
        "\n",
        "\n",
        "Vanligvis ville vi ha skrevet datasettet tilbake til BigQuery, men det gj칮r vi ikke i denne workshopen. (Det tok lang tid, vi har mye data游땺) \n",
        "\n",
        "Pandas har en ganske snedig funksjon som kan gj칮re dette!\n",
        "\n",
        "```df_merged.to_gbq(\"bysykkel_main.bysykkel_med_v칝rdata\", project_id=\"data-intro\")```\n",
        "\n",
        "N친r vi skriver til BigQuery, vil datatypene i dataframen f칮lge med og sette riktig skjema i BigQuery\n"
      ],
      "metadata": {
        "id": "vUZMf3ycUY7D"
      }
    }
  ]
}